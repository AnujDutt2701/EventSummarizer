import DataPreparation.PreProcessData as ppd
import nltk
# tagged_sents = brown.tagged_sents(categories='news')
# print(tagged_sents)
import pickle



def pos_features(sentence, i):
    features = {"suffix(1)": sentence[i][-1:],
                "suffix(2)": sentence[i][-2:],
                "suffix(3)": sentence[i][-3:]}
    if i == 0:
        features["prev-word"] = "<START>"
    else:
        features["prev-word"] = sentence[i - 1]
    return features


featuresets = []
test_df = ppd.read_data('../DataPreparation/2018-03-17-2019-03-17.csv')
notes = test_df['notes'].tolist()
tagged_sents = []



for note in notes:
    tagged_sents.append(nltk.pos_tag(nltk.word_tokenize(note)))

# TODO: The above for loop can be relplaced with someting similar like below
# tagged_texts = pos_tag_sents(map(word_tokenize, notes))
# tagged_texts

print(tagged_sents)
for tagged_sent in tagged_sents:
    untagged_sent = nltk.tag.untag(tagged_sent)
    for i, (word, tag) in enumerate(tagged_sent):
        featuresets.append((pos_features(untagged_sent, i), tag) )

print(featuresets)

classifier = pickle.load(open("classifier.p", "rb"))

# size = int(len(featuresets) * 0.1)
# train_set, test_set = featuresets[size:], featuresets[:size]
# classifier = nltk.NaiveBayesClassifier.train(train_set)
output = classifier.classify(featuresets[0])
# nltk.classify.accuracy(classifier, test_set)
# print(classifier.classify(test_set))